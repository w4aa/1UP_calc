---
phase: 01-change-detection
plan: 01
type: execute
---

<objective>
Implement 1x2 odds comparison logic to determine when scraping is needed.

Purpose: Enable change-based scraping so the system only collects competitor data when BetPawa 1x2 odds actually shift, reducing unnecessary API calls and focusing on meaningful market movements.

Output: Working change detection that compares new BetPawa 1x2 odds against the most recent market_snapshot, with updated database methods and integration into the scraping flow.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@src/db/manager.py
@src/unified_scraper.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update DatabaseManager with snapshot-based comparison method</name>
  <files>src/db/manager.py</files>
  <action>Add method `get_latest_snapshot_1x2_odds(sportradar_id, bookmaker)` that queries market_snapshots table joined with scraping_history to get the most recent 1x2 odds for a specific event and bookmaker. Return tuple of (home_odds, draw_odds, away_odds) or None if no snapshots exist. Join on sportradar_id and order by scraping_history.scraped_at DESC LIMIT 1. Then update `check_1x2_odds_changed` method to call this new method instead of reading from events table cache fields. Keep the tolerance parameter at 0.01 default. The comparison should use the snapshot data as source of truth, not the events table cache.</action>
  <verify>python -c "from src.db.manager import DatabaseManager; db = DatabaseManager('data/datas.db'); db.connect(); print('Methods exist:', hasattr(db, 'get_latest_snapshot_1x2_odds'))"</verify>
  <done>Method get_latest_snapshot_1x2_odds exists, returns correct data structure (tuple or None), check_1x2_odds_changed uses snapshot-based comparison</done>
</task>

<task type="auto">
  <name>Task 2: Verify change detection integration in unified scraper</name>
  <files>src/unified_scraper.py</files>
  <action>Review the existing change detection calls at lines ~422 and ~566 in unified_scraper.py. Verify they correctly call db.check_1x2_odds_changed with BetPawa odds (not Sportybet odds). The check should happen for BetPawa bookmaker specifically since the requirement states "compare new BetPawa 1x2 odds against last market_snapshot". If the current code checks Sportybet or Pawa separately, ensure only BetPawa triggers scraping decisions. Update logic if needed so that when BetPawa 1x2 odds change, ALL bookmakers get scraped (Sportybet, BetPawa, Bet9ja) to maintain data consistency.</action>
  <verify>grep -n "check_1x2_odds_changed" src/unified_scraper.py shows correct usage with bookmaker='pawa'</verify>
  <done>Change detection correctly checks BetPawa odds against last snapshot, triggers full scrape (all bookmakers) when BetPawa 1x2 changes</done>
</task>

<task type="auto">
  <name>Task 3: Add unit test for snapshot-based comparison</name>
  <files>tests/test_change_detection.py</files>
  <action>Create new test file test_change_detection.py. Test scenarios: (1) No previous snapshot returns True (always scrape), (2) Identical odds within tolerance returns False (skip scrape), (3) Odds changed beyond tolerance returns True (scrape needed), (4) Different bookmakers tracked independently. Use in-memory SQLite database (:memory:) for tests. Create test fixtures that insert mock scraping_history and market_snapshots records. Verify get_latest_snapshot_1x2_odds returns correct data and check_1x2_odds_changed makes correct decisions.</action>
  <verify>python tests/test_change_detection.py runs without errors, all tests pass</verify>
  <done>Test file exists with 4+ test cases, all passing, covering core change detection scenarios</done>
</task>

</tasks>

<verification>
Before declaring phase complete:
- [ ] `python tests/test_change_detection.py` passes all tests
- [ ] `get_latest_snapshot_1x2_odds` method exists in DatabaseManager
- [ ] `check_1x2_odds_changed` uses snapshot data (not events table cache)
- [ ] unified_scraper.py correctly integrates BetPawa-based change detection
- [ ] No syntax errors in modified files
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- Change detection uses market_snapshots table as source of truth
- BetPawa 1x2 odds changes trigger full scrape (all bookmakers)
- Unit tests validate comparison logic
- No breaking changes to existing functionality
</success_criteria>

<output>
After completion, create `.planning/phases/01-change-detection/01-01-SUMMARY.md`:

# Phase 1 Plan 1: Change Detection Foundation Summary

**Implemented snapshot-based 1x2 odds comparison for change-driven scraping.**

## Accomplishments

- Added DatabaseManager method to query latest snapshot 1x2 odds
- Updated change detection to use market_snapshots instead of events cache
- Verified BetPawa-based comparison triggers scraping correctly
- Created comprehensive unit tests for change detection logic

## Files Created/Modified

- `src/db/manager.py` - Added get_latest_snapshot_1x2_odds, updated check_1x2_odds_changed
- `src/unified_scraper.py` - Verified/updated BetPawa change detection integration
- `tests/test_change_detection.py` - Created test suite

## Decisions Made

- Use market_snapshots table as source of truth for odds comparison (not events cache)
- BetPawa 1x2 odds change triggers scraping all bookmakers (maintains data consistency)
- Keep 0.01 tolerance for odds change detection

## Issues Encountered

None or [specific issues and resolutions]

## Next Phase Readiness

Phase 1 complete. Ready for Phase 2: Integrated Scraping Flow.
</output>
